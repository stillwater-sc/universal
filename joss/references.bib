%%% =========================================================
%%% BibTeX-file{
%%% 	title		= "Universal Numbers Library"
%%%     author          = "Omtzigt, E.T.L & Quinlan, J.",
%%%     version         = "1.00",
%%%     date            = "09 Jan 2023",
%%%     filename        = "references.bib",
%%%     keywords        = "Universal Numbers Library"
%%%     AMS             = "65G50, 65F10",
%%%     }
%%% =========================================================


@inproceedings{carmichael:2019,
  title={Deep positron: A deep neural network using the posit number system},
  author={Carmichael, Zachariah and Langroudi, Hamed F and Khazanov, Char and Lillie, Jeffrey and Gustafson, John L and Kudithipudi, Dhireesha},
  booktitle={2019 Design, Automation \& Test in Europe Conference \& Exhibition (DATE)},
  pages={1421--1426},
  year={2019},
  organization={IEEE}
}


@article{carson:2018,
  title={Accelerating the solution of linear systems by iterative refinement in three precisions},
  author={Carson, Erin and Higham, Nicholas J},
  journal={SIAM Journal on Scientific Computing},
  volume={40},
  number={2},
  pages={A817--A847},
  year={2018},
  publisher={SIAM}
}


@article{choquette2021nvidia,
  title={NVIDIA A100 tensor core GPU: Performance and innovation},
  author={Choquette, Jack and Gandhi, Wishwesh and Giroux, Olivier and Stam, Nick and Krashinsky, Ronny},
  journal={IEEE Micro},
  volume={41},
  number={2},
  pages={29--35},
  year={2021},
  publisher={IEEE}
}


@inproceedings{cococcioni2022small,
  title={Small reals representations for Deep Learning at the edge: a comparison},
  author={Cococcioni, Marco and Rossi, Federico and Emanuele, Ruffaldi and Saponara, Sergio},
  booktitle={Proc. of the 2022 Conference on Next Generation Arithmetic (CoNGA'22)},
  year={2022}
}


@inproceedings{desrentes:2022posit8,
  title={A Posit8 Decompression Operator for Deep Neural Network Inference},
  author={Desrentes, Or{\'e}gane and Resmerita, Diana and de Dinechin, BenoË†{\i}t Dupont},
  booktitle={Next Generation Arithmetic: Third International Conference, CoNGA 2022, Singapore, March 1--3, 2022, Revised Selected Papers},
  volume={13253},
  pages={14},
  year={2022},
  organization={Springer Nature}
}


@inproceedings{haidar:2018a,
  title={Harnessing {GPU} tensor cores for fast {FP16} arithmetic to speed up mixed-precision iterative refinement solvers},
  author={Haidar, Azzam and Tomov, Stanimire and Dongarra, Jack and Higham, Nicholas J},
  booktitle={SC18: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={603--613},
  year={2018},
  organization={IEEE}
}


@inproceedings{haidar:2017,
  title={Investigating half precision arithmetic to accelerate dense linear system solvers},
  author={Haidar, Azzam and Wu, Panruo and Tomov, Stanimire and Dongarra, Jack},
  booktitle={Proceedings of the 8th Workshop on Latest Advances in Scalable Algorithms for Large-Scale Systems},
  pages={1--8},
  year={2017}
}


@inproceedings{haidar:2018b,
  title={The design of fast and energy-efficient linear solvers: On the potential of half-precision arithmetic and iterative refinement techniques},
  author={Haidar, Azzam and Abdelfattah, Ahmad and Zounon, Mawussi and Wu, Panruo and Pranesh, Srikara and Tomov, Stanimire and Dongarra, Jack},
  booktitle={International Conference on Computational Science},
  pages={586--600},
  year={2018},
  organization={Springer}
}


@article{higham:2019,
  title={Squeezing a matrix into half precision, with an application to solving linear systems},
  author={Higham, Nicholas J and Pranesh, Srikara and Zounon, Mawussi},
  journal={SIAM Journal on Scientific Computing},
  volume={41},
  number={4},
  pages={A2536--A2551},
  year={2019},
  publisher={SIAM}
}


@article{intel:2018,
  title={{BFLOAT16} - {H}ardware {N}umerics {D}efinition},
  author={{Intel Corporation}},
  journal={},
  volume={},
  number={},
  pages={},
  year={2018},
  publisher={Intel}, 
  url={https://www.intel.com/content/dam/develop/external/us/en/documents/bf16-hardware-numerics-definition-white-paper.pdf}
}


@article{kharya:2020,
  title={TensorFloat-32 in the A100 GPU accelerates AI training HPC up to 20x},
  author={Kharya, P},
  url={https://blogs.nvidia.com/blog/2020/05/14/tensorfloat-32-precision-format/},
  journal={NVIDIA Corporation, Tech. Rep},
  year={2020}
}

    
 @inproceedings{omtzigt:2022,
  title={Universal: Reliable, Reproducible, and Energy-Efficient Numerics},
  author={E. Theodore L. Omtzigt and James Quinlan},
  booktitle={Conference on Next Generation Arithmetic},
  pages={100--116},
  year={2022},
  organization={Springer}
}


@article{omtzigt:2020,
    author    = {E. Theodore L. Omtzigt and Peter Gottschling and Mark Seligman and William Zorn},
    title     = {{Universal Numbers Library}: design and implementation of a high-performance reproducible number systems library},
    journal   = {arXiv:2012.11011},
    year      = {2020},
}


@article{wang2019bfloat16,
  title={BFloat16: The secret to high performance on Cloud TPUs},
  author={Wang, Shibo and Kanwar, Pankaj},
  journal={Google Cloud Blog},
  volume={4},
  year={2019}
}
