%%% =========================================================
%%% BibTeX-file{
%%% 	title		= "Universal Systems Paper References"
%%%     author          = "Omtzigt, E.T.L & Quinlan, J.",
%%%     version         = "1.00",
%%%     date            = "09 Feb 2026",
%%%     filename        = "references.bib",
%%%     keywords        = "Universal Numbers Library, Block Formats, Mixed Precision"
%%%     AMS             = "65G50, 65F10",
%%%     }
%%% =========================================================
%%%
%%% Existing entries from joss/references.bib
%%% =========================================================

@inproceedings{carmichael:2019,
  title={Deep positron: A deep neural network using the posit number system},
  author={Carmichael, Zachariah and Langroudi, Hamed F and Khazanov, Char and Lillie, Jeffrey and Gustafson, John L and Kudithipudi, Dhireesha},
  booktitle={2019 Design, Automation \& Test in Europe Conference \& Exhibition (DATE)},
  pages={1421--1426},
  year={2019},
  doi={10.23919/date.2019.8715262},
  organization={IEEE}
}

@article{carson:2018,
  title={Accelerating the solution of linear systems by iterative refinement in three precisions},
  author={Carson, Erin and Higham, Nicholas J},
  journal={SIAM Journal on Scientific Computing},
  volume={40},
  number={2},
  pages={A817--A847},
  year={2018},
  doi={10.1137/17m1140819},
  publisher={SIAM}
}

@article{choquette2021nvidia,
  title={NVIDIA A100 tensor core GPU: Performance and innovation},
  author={Choquette, Jack and Gandhi, Wishwesh and Giroux, Olivier and Stam, Nick and Krashinsky, Ronny},
  journal={IEEE Micro},
  volume={41},
  number={2},
  pages={29--35},
  year={2021},
  doi={10.1109/mm.2021.3061394},
  publisher={IEEE}
}

@inproceedings{cococcioni2022small,
  title={Small reals representations for Deep Learning at the edge: a comparison},
  author={Cococcioni, Marco and Rossi, Federico and Emanuele, Ruffaldi and Saponara, Sergio},
  booktitle={Proc. of the 2022 Conference on Next Generation Arithmetic (CoNGA'22)},
  year={2022}
}

@inproceedings{desrentes:2022posit8,
  title={A Posit8 Decompression Operator for Deep Neural Network Inference},
  author={Desrentes, Or{\'e}gane and Resmerita, Diana and de Dinechin, BenoË†{\i}t Dupont},
  booktitle={Next Generation Arithmetic: Third International Conference, CoNGA 2022, Singapore, March 1--3, 2022, Revised Selected Papers},
  volume={13253},
  pages={14},
  year={2022},
  doi={10.1007/978-3-031-09779-9_2},
  organization={Springer Nature}
}

@inproceedings{haidar:2018a,
  title={Harnessing {GPU} tensor cores for fast {FP16} arithmetic to speed up mixed-precision iterative refinement solvers},
  author={Haidar, Azzam and Tomov, Stanimire and Dongarra, Jack and Higham, Nicholas J},
  booktitle={SC18: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={603--613},
  year={2018},
  doi={10.1109/sc.2018.00050},
  organization={IEEE}
}

@inproceedings{haidar:2017,
  title={Investigating half precision arithmetic to accelerate dense linear system solvers},
  author={Haidar, Azzam and Wu, Panruo and Tomov, Stanimire and Dongarra, Jack},
  booktitle={Proceedings of the 8th Workshop on Latest Advances in Scalable Algorithms for Large-Scale Systems},
  pages={1--8},
  doi={10.1145/3148226.3148237},
  year={2017}
}

@inproceedings{haidar:2018b,
  title={The design of fast and energy-efficient linear solvers: On the potential of half-precision arithmetic and iterative refinement techniques},
  author={Haidar, Azzam and Abdelfattah, Ahmad and Zounon, Mawussi and Wu, Panruo and Pranesh, Srikara and Tomov, Stanimire and Dongarra, Jack},
  booktitle={International Conference on Computational Science},
  pages={586--600},
  year={2018},
  doi={10.1007/978-3-319-93698-7_45},
  organization={Springer}
}

@article{higham:2019,
  title={Squeezing a matrix into half precision, with an application to solving linear systems},
  author={Higham, Nicholas J and Pranesh, Srikara and Zounon, Mawussi},
  journal={SIAM Journal on Scientific Computing},
  volume={41},
  number={4},
  pages={A2536--A2551},
  year={2019},
  doi={10.1137/18m1229511},
  publisher={SIAM}
}

@article{intel:2018,
  title={{BFLOAT16} -- {H}ardware {N}umerics {D}efinition},
  author={{Intel Corporation}},
  year={2018},
  publisher={Intel},
  url={https://www.intel.com/content/dam/develop/external/us/en/documents/bf16-hardware-numerics-definition-white-paper.pdf}
}

@article{kharya:2020,
  title={TensorFloat-32 in the {A100} {GPU} accelerates {AI} training, {HPC} up to 20x},
  author={Kharya, Paresh},
  journal={NVIDIA Corporation, Tech. Rep.},
  year={2020},
  url={https://blogs.nvidia.com/blog/2020/05/14/tensorfloat-32-precision-format/}
}

@inproceedings{omtzigt:2022,
  title={Universal: Reliable, Reproducible, and Energy-Efficient Numerics},
  author={E. Theodore L. Omtzigt and James Quinlan},
  booktitle={Conference on Next Generation Arithmetic},
  pages={100--116},
  year={2022},
  doi={10.1007/978-3-031-09779-9_7},
  organization={Springer}
}

@article{omtzigt:2020,
  author={E. Theodore L. Omtzigt and Peter Gottschling and Mark Seligman and William Zorn},
  title={{Universal Numbers Library}: design and implementation of a high-performance reproducible number systems library},
  journal={arXiv:2012.11011},
  year={2020}
}

@article{wang2019bfloat16,
  title={BFloat16: The secret to high performance on Cloud {TPUs}},
  author={Wang, Shibo and Kanwar, Pankaj},
  journal={Google Cloud Blog},
  volume={4},
  year={2019}
}

%%% =========================================================
%%% New entries for the systems paper
%%% =========================================================

@book{gustafson:2017,
  title={The End of Error: Unum Computing},
  author={Gustafson, John L},
  year={2017},
  publisher={Chapman and Hall/CRC},
  edition={2nd},
  isbn={978-1482239867}
}

@standard{ieee754:2019,
  title={{IEEE} Standard for Floating-Point Arithmetic},
  author={{IEEE}},
  journal={IEEE Std 754-2019 (Revision of IEEE 754-2008)},
  pages={1--84},
  year={2019},
  doi={10.1109/IEEESTD.2019.8766229},
  publisher={IEEE}
}

@techreport{ocp_mx:2023,
  title={{OCP} Microscaling Formats ({MX}) Specification, Version 1.0},
  author={{Open Compute Project}},
  year={2023},
  institution={Open Compute Project Foundation},
  url={https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf}
}

@inproceedings{nvidia_fp4:2024,
  title={Blackwell Architecture Technical Brief},
  author={{NVIDIA Corporation}},
  year={2024},
  note={NVIDIA B200 GPU with FP4 Tensor Cores},
  url={https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/}
}

@article{lindstrom:2014,
  title={Fixed-Rate Compressed Floating-Point Arrays},
  author={Lindstrom, Peter},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={20},
  number={12},
  pages={2674--2683},
  year={2014},
  doi={10.1109/TVCG.2014.2346458},
  publisher={IEEE}
}

@book{bailey:2005,
  title={High-Precision Floating-Point Arithmetic in Scientific Computation},
  author={Bailey, David H},
  year={2005},
  publisher={Computing in Science \& Engineering},
  volume={7},
  number={3},
  pages={54--61},
  doi={10.1109/MCSE.2005.52}
}

@article{horowitz:2014,
  title={1.1 Computing's energy problem (and what we can do about it)},
  author={Horowitz, Mark},
  journal={IEEE International Solid-State Circuits Conference Digest of Technical Papers (ISSCC)},
  pages={10--14},
  year={2014},
  doi={10.1109/ISSCC.2014.6757323},
  publisher={IEEE}
}

@article{sonneveld:2008,
  title={{IDR}(s): A Family of Simple and Fast Algorithms for Solving Large Nonsymmetric Systems of Linear Equations},
  author={Sonneveld, Peter and van Gijzen, Martin B},
  journal={SIAM Journal on Scientific Computing},
  volume={31},
  number={2},
  pages={1035--1062},
  year={2008},
  doi={10.1137/070685804},
  publisher={SIAM}
}

@article{vangijzen:2011,
  title={Algorithm 913: An Elegant {IDR}(s) Variant that Efficiently Exploits Biorthogonality Properties},
  author={van Gijzen, Martin B and Sonneveld, Peter},
  journal={ACM Transactions on Mathematical Software},
  volume={38},
  number={1},
  pages={1--19},
  year={2011},
  doi={10.1145/2049662.2049667},
  publisher={ACM}
}

@book{higham:2002,
  title={Accuracy and Stability of Numerical Algorithms},
  author={Higham, Nicholas J},
  year={2002},
  edition={2nd},
  publisher={SIAM},
  isbn={978-0-89871-521-7},
  doi={10.1137/1.9780898718027}
}

@book{saad:2003,
  title={Iterative Methods for Sparse Linear Systems},
  author={Saad, Yousef},
  year={2003},
  edition={2nd},
  publisher={SIAM},
  isbn={978-0-89871-534-7},
  doi={10.1137/1.9780898718003}
}

@article{fousse:2007,
  title={{MPFR}: A Multiple-Precision Binary Floating-Point Library with Correct Rounding},
  author={Fousse, Laurent and Hanrot, Guillaume and Lef{\`e}vre, Vincent and P{\'e}lissier, Patrick and Zimmermann, Paul},
  journal={ACM Transactions on Mathematical Software},
  volume={33},
  number={2},
  pages={13},
  year={2007},
  doi={10.1145/1236463.1236468},
  publisher={ACM}
}

@inproceedings{flegar:2019,
  title={{FloatX}: A {C++} Library for Customized Floating-Point Arithmetic},
  author={Flegar, Goran and Scheidegger, Florian and Novakovi{\'c}, Vedran and Mariani, Giovani and Tom{\'a}s, Andr{\'e}s E and Malossi, A Cristiano I and Quintana-Ort{\'i}, Enrique S},
  journal={ACM Transactions on Mathematical Software},
  volume={45},
  number={4},
  pages={1--23},
  year={2019},
  doi={10.1145/3368086},
  publisher={ACM}
}

@inproceedings{dettmers:2022,
  title={{LLM.int8()}: 8-bit Matrix Multiplication for Transformers at Scale},
  author={Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30318--30332},
  year={2022}
}

@inproceedings{micikevicius:2018,
  title={Mixed Precision Training},
  author={Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and Wu, Hao},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}
